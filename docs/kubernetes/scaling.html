<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Kubernetes Scaling & Monitoring | K8s Docs</title>
  
  <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,400,600,700&display=swap" rel="stylesheet">
  <link href="../../assets/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
  <link href="../../assets/vendor/bootstrap-icons/bootstrap-icons.css" rel="stylesheet">
  
  <style>
    :root {
      --primary-color: #149ddd;
      --secondary-color: #173b6c;
      --text-color: #272829;
      --bg-light: #f5f8fd;
      --code-bg: #282c34;
      --code-text: #abb2bf;
    }
    
    body {
      font-family: 'Open Sans', sans-serif;
      background: var(--bg-light);
      color: var(--text-color);
      line-height: 1.8;
    }
    
    .sidebar {
      position: sticky;
      top: 20px;
      background: white;
      border-radius: 12px;
      padding: 2rem;
      box-shadow: 0 3px 15px rgba(0,0,0,0.08);
      height: fit-content;
      max-height: 90vh;
      overflow-y: auto;
    }
    
    .sidebar h5 {
      color: var(--primary-color);
      font-weight: 600;
      margin-bottom: 1.5rem;
    }
    
    .sidebar .nav-link {
      color: var(--text-color);
      padding: 0.5rem 0;
      border-left: 3px solid transparent;
      transition: all 0.3s;
    }
    
    .sidebar .nav-link:hover,
    .sidebar .nav-link.active {
      color: var(--primary-color);
      border-left-color: var(--primary-color);
      padding-left: 1rem;
    }
    
    .content {
      background: white;
      border-radius: 12px;
      padding: 3rem;
      box-shadow: 0 3px 15px rgba(0,0,0,0.08);
      margin-bottom: 2rem;
    }
    
    h1 {
      color: var(--secondary-color);
      font-weight: 700;
      margin-bottom: 1.5rem;
    }
    
    h2 {
      color: var(--primary-color);
      font-weight: 600;
      margin-top: 2.5rem;
      margin-bottom: 1.5rem;
      padding-bottom: 0.5rem;
      border-bottom: 2px solid var(--bg-light);
    }
    
    h3 {
      color: var(--secondary-color);
      font-weight: 600;
      margin-top: 2rem;
      margin-bottom: 1rem;
    }
    
    code {
      background: #f8f9fa;
      padding: 0.2rem 0.5rem;
      border-radius: 4px;
      font-family: 'Courier New', monospace;
      color: #e83e8c;
    }
    
    pre {
      background: var(--code-bg);
      border: 1px solid #e9ecef;
      border-radius: 8px;
      padding: 1.5rem;
      overflow-x: auto;
      margin: 1.5rem 0;
    }
    
    pre code {
      background: none;
      padding: 0;
      color: var(--code-text);
      font-family: 'Courier New', monospace;
    }
    
    .navbar {
      background: white;
      box-shadow: 0 2px 15px rgba(0,0,0,0.1);
      margin-bottom: 2rem;
    }
    
    .breadcrumb {
      background: transparent;
      padding: 0;
      margin-bottom: 2rem;
    }
    
    .breadcrumb a {
      color: var(--primary-color);
      text-decoration: none;
    }
    
    .tip-box {
      background: #e7f3ff;
      border-left: 4px solid #007bff;
      padding: 1rem 1.5rem;
      margin: 1.5rem 0;
      border-radius: 6px;
    }
    
    .warning-box {
      background: #fff3cd;
      border-left: 4px solid #ffc107;
      padding: 1rem 1.5rem;
      margin: 1.5rem 0;
      border-radius: 6px;
    }
    
    .info-card {
      background: var(--bg-light);
      border-radius: 8px;
      padding: 1.5rem;
      margin: 1rem 0;
      border-left: 4px solid var(--primary-color);
    }
    
    .info-card h4 {
      color: var(--primary-color);
      margin-bottom: 0.5rem;
    }
  </style>
</head>
<body>

  <!-- Navigation -->
  <nav class="navbar navbar-expand-lg navbar-light">
    <div class="container-fluid">
      <div class="container">
        <a class="navbar-brand" href="../../index.html">
          <i class="bi bi-house-door me-2"></i>Lê Bình Phương
        </a>
      </div>
    </div>
  </nav>

  <div class="container">
    
    <!-- Breadcrumb -->
    <nav aria-label="breadcrumb">
      <ol class="breadcrumb">
        <li class="breadcrumb-item"><a href="../../index.html">Home</a></li>
        <li class="breadcrumb-item"><a href="../index.html">Documents</a></li>
        <li class="breadcrumb-item"><a href="index.html">Kubernetes</a></li>
        <li class="breadcrumb-item active">Scaling & Monitoring</li>
      </ol>
    </nav>

    <div class="row">
      
      <!-- Sidebar -->
      <div class="col-lg-3">
        <div class="sidebar">
          <h5><i class="bi bi-cloud-fill me-2"></i>Kubernetes</h5>
          <nav class="nav flex-column">
            <a class="nav-link" href="index.html">Getting Started</a>
            <a class="nav-link" href="concepts.html">Core Concepts</a>
            <a class="nav-link" href="deployment.html">Deployment Guide</a>
            <a class="nav-link active" href="scaling.html">Scaling & Monitoring</a>
          </nav>
        </div>
      </div>

      <!-- Main Content -->
      <div class="col-lg-9">
        <div class="content">
          <h1><i class="bi bi-graph-up-arrow me-2"></i>Scaling & Monitoring</h1>
          
          <p>
            Learn how to scale your Kubernetes applications automatically and monitor them effectively 
            using various scaling strategies and monitoring tools.
          </p>

          <h2>Manual Scaling</h2>

          <h3>Scale Deployment</h3>
          <pre><code># Scale to specific number of replicas
kubectl scale deployment/myapp --replicas=5

# Scale all deployments in namespace
kubectl scale deployment --all --replicas=3 -n production

# Scale ReplicaSet
kubectl scale rs/myapp-rs --replicas=5

# Scale StatefulSet
kubectl scale statefulset/myapp-sts --replicas=3</code></pre>

          <h3>Scale ReplicationController</h3>
          <pre><code>kubectl scale rc/myapp-rc --replicas=5</code></pre>

          <h2>Horizontal Pod Autoscaler (HPA)</h2>

          <div class="info-card">
            <h4>What is HPA?</h4>
            <p>
              HPA automatically scales the number of Pods in a deployment, replica set, or stateful set 
              based on observed CPU, memory utilization, or custom metrics.
            </p>
          </div>

          <h3>Prerequisites</h3>
          <p>Install Metrics Server:</p>
          <pre><code># Install metrics server
kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml

# Verify installation
kubectl get deployment metrics-server -n kube-system

# Test metrics
kubectl top nodes
kubectl top pods</code></pre>

          <h3>Basic HPA Example</h3>
          <pre><code>apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: myapp-hpa
  namespace: production
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: myapp-deployment
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
      - type: Percent
        value: 50
        periodSeconds: 60
    scaleUp:
      stabilizationWindowSeconds: 0
      policies:
      - type: Percent
        value: 100
        periodSeconds: 30
      - type: Pods
        value: 2
        periodSeconds: 30
      selectPolicy: Max</code></pre>

          <h3>HPA Commands</h3>
          <pre><code># Create HPA
kubectl apply -f hpa.yaml

# Create HPA from command line
kubectl autoscale deployment/myapp-deployment \
  --min=2 \
  --max=10 \
  --cpu-percent=70

# Get HPA status
kubectl get hpa

# Describe HPA
kubectl describe hpa myapp-hpa

# Delete HPA
kubectl delete hpa myapp-hpa</code></pre>

          <h2>Vertical Pod Autoscaler (VPA)</h2>

          <div class="info-card">
            <h4>What is VPA?</h4>
            <p>
              VPA automatically adjusts CPU and memory requests/limits for containers in Pods based on 
              historical and current resource usage.
            </p>
          </div>

          <h3>VPA Example</h3>
          <pre><code>apiVersion: autoscaling.k8s.io/v1
kind: VerticalPodAutoscaler
metadata:
  name: myapp-vpa
spec:
  targetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: myapp-deployment
  updatePolicy:
    updateMode: "Auto"  # Auto, Initial, Recreate, Off
  resourcePolicy:
    containerPolicies:
    - containerName: myapp
      minAllowed:
        cpu: 100m
        memory: 128Mi
      maxAllowed:
        cpu: 2
        memory: 2Gi
      controlledResources: ["cpu", "memory"]</code></pre>

          <h2>Cluster Autoscaler</h2>

          <div class="info-card">
            <h4>What is Cluster Autoscaler?</h4>
            <p>
              Cluster Autoscaler automatically adjusts the number of nodes in your cluster when:
              <ul>
                <li>Pods fail to schedule due to insufficient resources</li>
                <li>Nodes are underutilized for extended periods</li>
              </ul>
            </p>
          </div>

          <h3>Cluster Autoscaler Configuration</h3>
          <pre><code>apiVersion: apps/v1
kind: Deployment
metadata:
  name: cluster-autoscaler
  namespace: kube-system
spec:
  replicas: 1
  selector:
    matchLabels:
      app: cluster-autoscaler
  template:
    metadata:
      labels:
        app: cluster-autoscaler
    spec:
      containers:
      - name: cluster-autoscaler
        image: k8s.gcr.io/autoscaling/cluster-autoscaler:v1.24.0
        command:
        - ./cluster-autoscaler
        - --v=4
        - --stderrthreshold=info
        - --cloud-provider=aws
        - --skip-nodes-with-local-storage=false
        - --expander=least-waste
        - --node-group-auto-discovery=asg:tag=k8s.io/cluster-autoscaler/enabled,k8s.io/cluster-autoscaler/my-cluster
        - --balance-similar-node-groups
        - --scale-down-enabled=true
        - --scale-down-delay-after-add=10m
        - --scale-down-unneeded-time=10m
        resources:
          limits:
            cpu: 100m
            memory: 300Mi
          requests:
            cpu: 100m
            memory: 300Mi</code></pre>

          <h2>Monitoring Stack</h2>

          <h3>Prometheus Setup</h3>
          <pre><code># Install Prometheus Operator
kubectl create namespace monitoring
kubectl apply -f https://raw.githubusercontent.com/prometheus-operator/prometheus-operator/main/bundle.yaml

# Create Prometheus instance
apiVersion: monitoring.coreos.com/v1
kind: Prometheus
metadata:
  name: prometheus
  namespace: monitoring
spec:
  replicas: 2
  serviceAccountName: prometheus
  serviceMonitorSelector:
    matchLabels:
      team: frontend
  resources:
    requests:
      memory: 2Gi
      cpu: 1000m</code></pre>

          <h3>Grafana Setup</h3>
          <pre><code>apiVersion: apps/v1
kind: Deployment
metadata:
  name: grafana
  namespace: monitoring
spec:
  replicas: 1
  selector:
    matchLabels:
      app: grafana
  template:
    metadata:
      labels:
        app: grafana
    spec:
      containers:
      - name: grafana
        image: grafana/grafana:latest
        ports:
        - containerPort: 3000
        env:
        - name: GF_SECURITY_ADMIN_PASSWORD
          valueFrom:
            secretKeyRef:
              name: grafana-secret
              key: admin-password
        volumeMounts:
        - name: grafana-storage
          mountPath: /var/lib/grafana
        resources:
          requests:
            memory: 256Mi
            cpu: 100m
          limits:
            memory: 512Mi
            cpu: 500m
      volumes:
      - name: grafana-storage
        persistentVolumeClaim:
          claimName: grafana-pvc

---
apiVersion: v1
kind: Service
metadata:
  name: grafana
  namespace: monitoring
spec:
  selector:
    app: grafana
  ports:
  - port: 3000
    targetPort: 3000
  type: LoadBalancer</code></pre>

          <h2>Application Metrics</h2>

          <h3>Exposing Metrics in Application</h3>
          <pre><code># Example: Node.js application
const express = require('express');
const client = require('prom-client');

const app = express();
const register = new client.Registry();

// Collect default metrics
client.collectDefaultMetrics({ register });

// Custom metrics
const httpRequestDuration = new client.Histogram({
  name: 'http_request_duration_seconds',
  help: 'Duration of HTTP requests in seconds',
  labelNames: ['method', 'route', 'status_code'],
  buckets: [0.1, 0.3, 0.5, 0.7, 1, 3, 5, 7, 10]
});

register.registerMetric(httpRequestDuration);

// Metrics endpoint
app.get('/metrics', async (req, res) => {
  res.set('Content-Type', register.contentType);
  res.end(await register.metrics());
});

app.listen(8080);</code></pre>

          <h3>ServiceMonitor for Prometheus</h3>
          <pre><code>apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: myapp-metrics
  namespace: production
  labels:
    team: backend
spec:
  selector:
    matchLabels:
      app: myapp
  endpoints:
  - port: http
    path: /metrics
    interval: 30s
    scrapeTimeout: 10s</code></pre>

          <h2>Logging</h2>

          <h3>Fluentd DaemonSet</h3>
          <pre><code>apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: fluentd
  namespace: kube-system
spec:
  selector:
    matchLabels:
      name: fluentd
  template:
    metadata:
      labels:
        name: fluentd
    spec:
      containers:
      - name: fluentd
        image: fluent/fluentd-kubernetes-daemonset:v1-debian-elasticsearch
        env:
        - name: FLUENT_ELASTICSEARCH_HOST
          value: "elasticsearch.logging.svc.cluster.local"
        - name: FLUENT_ELASTICSEARCH_PORT
          value: "9200"
        volumeMounts:
        - name: varlog
          mountPath: /var/log
        - name: varlibdockercontainers
          mountPath: /var/lib/docker/containers
          readOnly: true
      volumes:
      - name: varlog
        hostPath:
          path: /var/log
      - name: varlibdockercontainers
        hostPath:
          path: /var/lib/docker/containers</code></pre>

          <h3>ELK Stack Setup</h3>
          <pre><code># Elasticsearch
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: elasticsearch
  namespace: logging
spec:
  serviceName: elasticsearch
  replicas: 3
  selector:
    matchLabels:
      app: elasticsearch
  template:
    metadata:
      labels:
        app: elasticsearch
    spec:
      containers:
      - name: elasticsearch
        image: docker.elastic.co/elasticsearch/elasticsearch:8.0.0
        env:
        - name: discovery.type
          value: single-node
        - name: "ES_JAVA_OPTS"
          value: "-Xms512m -Xmx512m"
        resources:
          requests:
            memory: 512Mi
            cpu: 500m
          limits:
            memory: 1Gi
            cpu: 1000m
        volumeMounts:
        - name: data
          mountPath: /usr/share/elasticsearch/data
  volumeClaimTemplates:
  - metadata:
      name: data
    spec:
      accessModes: [ "ReadWriteOnce" ]
      resources:
        requests:
          storage: 20Gi</code></pre>

          <h2>Alerting</h2>

          <h3>Prometheus Alertmanager</h3>
          <pre><code>apiVersion: v1
kind: ConfigMap
metadata:
  name: alertmanager-config
  namespace: monitoring
data:
  alertmanager.yml: |
    global:
      resolve_timeout: 5m
    route:
      group_by: ['alertname']
      group_wait: 10s
      group_interval: 10s
      repeat_interval: 12h
      receiver: 'web.hook'
    receivers:
    - name: 'web.hook'
      webhook_configs:
      - url: 'http://alert-receiver:5001/'

---
apiVersion: monitoring.coreos.com/v1
kind: Alertmanager
metadata:
  name: main
  namespace: monitoring
spec:
  replicas: 2
  configSecret: alertmanager-config</code></pre>

          <h3>PrometheusRule Example</h3>
          <pre><code>apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: myapp-alerts
  namespace: monitoring
spec:
  groups:
  - name: myapp.rules
    rules:
    - alert: HighCPUUsage
      expr: rate(container_cpu_usage_seconds_total[5m]) > 0.8
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "High CPU usage detected"
        description: "CPU usage is above 80% for 5 minutes"
    
    - alert: PodCrashLooping
      expr: rate(kube_pod_container_status_restarts_total[15m]) > 0
      for: 5m
      labels:
        severity: critical
      annotations:
        summary: "Pod is crash looping"
        description: "Pod {{ $labels.pod }} is restarting frequently"</code></pre>

          <h2>Observability Commands</h2>

          <h3>Resource Monitoring</h3>
          <pre><code># Get node metrics
kubectl top nodes

# Get pod metrics
kubectl top pods

# Get pod metrics in namespace
kubectl top pods -n production

# Get pod metrics with labels
kubectl top pods -l app=myapp

# Get pod metrics sorted by CPU
kubectl top pods --sort-by=cpu

# Get pod metrics sorted by memory
kubectl top pods --sort-by=memory</code></pre>

          <h3>Log Commands</h3>
          <pre><code># Get pod logs
kubectl logs &lt;pod-name&gt;

# Follow logs
kubectl logs -f &lt;pod-name&gt;

# Get logs from all containers in pod
kubectl logs &lt;pod-name&gt; --all-containers=true

# Get logs from specific container
kubectl logs &lt;pod-name&gt; -c &lt;container-name&gt;

# Get logs with timestamp
kubectl logs &lt;pod-name&gt; --timestamps

# Get logs since specific time
kubectl logs &lt;pod-name&gt; --since=1h

# Get logs from previous container
kubectl logs &lt;pod-name&gt; --previous

# Get logs from all pods with label
kubectl logs -l app=myapp --tail=100</code></pre>

          <h2>Best Practices</h2>

          <h3>Scaling Best Practices</h3>
          <ul>
            <li>✅ Set appropriate min/max replicas for HPA</li>
            <li>✅ Use resource requests and limits</li>
            <li>✅ Monitor and tune HPA metrics thresholds</li>
            <li>✅ Consider scaling policies for stability</li>
            <li>✅ Test scaling behavior under load</li>
          </ul>

          <h3>Monitoring Best Practices</h3>
          <ul>
            <li>✅ Monitor resource utilization (CPU, memory)</li>
            <li>✅ Monitor application metrics (requests, latency)</li>
            <li>✅ Set up alerting for critical issues</li>
            <li>✅ Use distributed tracing for microservices</li>
            <li>✅ Centralize logging with ELK or Loki</li>
            <li>✅ Monitor cluster health and capacity</li>
          </ul>

          <h2>Next Steps</h2>
          <ul>
            <li><strong><a href="deployment.html">Deployment Guide</a></strong> - Production deployment strategies</li>
            <li><strong><a href="concepts.html">Core Concepts</a></strong> - Deep dive into Kubernetes objects</li>
            <li><strong><a href="../refs/kubectl-cheatsheet.html">kubectl Cheatsheet</a></strong> - Quick reference</li>
          </ul>

        </div>
      </div>
    </div>
  </div>

  <script src="../../assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
</body>
</html>

